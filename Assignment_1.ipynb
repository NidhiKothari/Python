{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NidhiKothari/Python/blob/master/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LypvUSzbIcda"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "### **Data Wrangling, Feature Engineering, and Visualization**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtZevUgbIwEV",
        "colab_type": "toc"
      },
      "source": [
        ">[Assignment 1](#scrollTo=LypvUSzbIcda)\n",
        "\n",
        ">>>[Data Wrangling, Feature Engineering, and Visualization](#scrollTo=LypvUSzbIcda)\n",
        "\n",
        ">>[Problem Statement:](#scrollTo=k7qNQCahJIAV)\n",
        "\n",
        ">>>[Analyzing transportation in the State of Connecticut](#scrollTo=k7qNQCahJIAV)\n",
        "\n",
        ">[Part 1-Data Wrangling](#scrollTo=WaK9YgoJLqZe)\n",
        "\n",
        ">>>[QW1: Opening Data, Merging Data](#scrollTo=WaK9YgoJLqZe)\n",
        "\n",
        ">>>[Loading all spreadsheets in data frame](#scrollTo=lxQBjNYWvsRi)\n",
        "\n",
        ">>>[QW2: Filtering out missing data (5 pts)](#scrollTo=5DwWnY5CiCla)\n",
        "\n",
        ">>[QW3: Replacing missing data (5 pts)](#scrollTo=durQ9I6XvFPo)\n",
        "\n",
        ">>[QW4: Removing duplicates (5 pts)](#scrollTo=Q8181JAe8otF)\n",
        "\n",
        ">>>[QW5: Discretization and Binning (5 pts)](#scrollTo=b9Xv2q7PyG4l)\n",
        "\n",
        ">>>[Data Wrangling](#scrollTo=4VIODq7vBA7R)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7qNQCahJIAV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## **Problem Statement:**\n",
        "### **Analyzing transportation in the State of Connecticut**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaK9YgoJLqZe",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Part 1-Data Wrangling\n",
        "### QW1: Opening Data, Merging Data\n",
        "•\tRead in the economic (#1) and the population (#4) and geographic (#5) datasets into Python.\n",
        "o\tI’ve dirtied up the economic data to help you practice your skills. You can find the clean original data online as a reference. You need to clean this data up before you can use it.\n",
        "o\tSince it’s a small dataset, open it in Excel first and just look at it –notice the nasty header and extra blank row in the data in the economic data? Get rid of them by using code. (2.5 points)\n",
        "•\tJoin all the datasets together \n",
        "o\tYou’ll need to convert town name to all caps for the join to be successful. Syntax matters. (2.5 points)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcsRvreGMAva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading all the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import os\n",
        "import random as r\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxQBjNYWvsRi",
        "colab_type": "text"
      },
      "source": [
        "### Loading all spreadsheets in data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRw5T1trvofO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# function to get id from url:\n",
        "def get_urlid(drive_url):\n",
        "  url_id=[]\n",
        "  for eachurl in drive_url:\n",
        "    uid=str(eachurl).split('/')\n",
        "    uid=uid[-2]\n",
        "    url_id.append(uid)\n",
        "  return url_id \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST8nZboczpPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# creating list of all the urls of files to be used in this assignment to fetch ids : \n",
        "url_1='https://drive.google.com/file/d/1VTtPQBRA32gA7wrF60S0YsfeclNkH-5k/view?usp=sharing'\n",
        "url_2_91='https://drive.google.com/file/d/1KJMZ__ipxHze2h_SQ8-fduk817dyi97P/view?usp=sharing'\n",
        "url_2_95='https://drive.google.com/file/d/1E9ZLFsHejF9YQMx6w7iysqJLONj9Mo2U/view?usp=sharing'\n",
        "url_2_15='https://drive.google.com/file/d/1tCB04luoCErUHnJ2oC1E_08GnItthhjv/view?usp=sharing'\n",
        "url_3='https://drive.google.com/file/d/1c2bWkMjkJFrOoHsNiegWTXmYgnrjNacS/view?usp=sharing'\n",
        "url_4='https://drive.google.com/file/d/1bn_-mDniCoFQ09TTXUxv6P-gSNvTcQlf/view?usp=sharing'\n",
        "url_5='https://drive.google.com/file/d/1HVGyBJZbdM7udcbh3SSOkkFRFGTEHp2Y/view?usp=sharing'\n",
        "list_url=[url_1,url_2_91,url_2_95,url_2_15,url_3,url_4,url_5]\n",
        "list_id=get_urlid(list_url)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsi9hlPazklr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# loading data sets\n",
        "urlsub=\"https://drive.google.com/uc?export=download&id=\"\n",
        "#1.2015 American Community Survey (ACS) economic data\n",
        "df_1 = pd.DataFrame(pd.read_csv(urlsub+list_id[0], header = 0,skiprows=5,encoding=\"cp1252\",usecols=[0,1,2,3],thousands=','))\n",
        "#2.Highway descriptions\n",
        "df_2_91= pd.DataFrame(pd.read_csv(urlsub+list_id[1], header = 0,encoding=\"cp1252\",thousands=r','))\n",
        "df_2_95=pd.DataFrame(pd.read_csv(urlsub+list_id[2], header = 0,encoding=\"cp1252\",thousands=r','))\n",
        "df_2_15=pd.DataFrame(pd.read_csv(urlsub+list_id[3], header = 0,encoding=\"cp1252\",thousands=r','))\n",
        "#3.Average daily traffic (ADT) by route and town index\n",
        "df_3=pd.DataFrame(pd.read_csv(urlsub+list_id[4], header = 0,encoding=\"cp1252\",thousands=r','))\n",
        "#4 Population data\n",
        "df_4=pd.DataFrame(pd.read_csv(urlsub+list_id[5], header = 0,encoding=\"cp1252\",thousands=r','))\n",
        "#5 Geographic data\n",
        "df_5=pd.DataFrame(pd.read_csv(urlsub+list_id[6], header = 0,encoding=\"cp1252\",thousands=r','))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT2JGsUHzvUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting rid of rows which are completetly empty if any\n",
        "df_1_clean=df_1.dropna(how='all')\n",
        "df_2_91_clean=df_2_91.dropna(how='all')\n",
        "df_2_95_clean=df_2_95.dropna(how='all')\n",
        "df_2_15_clean=df_2_15.dropna(how='all')\n",
        "df_3_clean=df_3.dropna(how='all')\n",
        "df_4_clean=df_4.dropna(how='all')\n",
        "df_5_clean=df_5.dropna(how='all')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-TKeJxqO2hH",
        "colab_type": "code",
        "outputId": "848fe75e-c250-4243-9824-3a7702c705c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "#Aligning the format of the headers for all the data sets\n",
        "df_1_clean.columns = map(str.title, df_1_clean.columns)\n",
        "df_2_91_clean.columns = map(str.title, df_2_91_clean.columns)\n",
        "df_2_95_clean.columns = map(str.title, df_2_95_clean.columns)\n",
        "df_2_15_clean.columns = map(str.title, df_2_15_clean.columns)\n",
        "df_3_clean.columns = map(str.title, df_3_clean.columns)\n",
        "df_4_clean.columns = map(str.title, df_4_clean.columns)\n",
        "df_5_clean.columns = map(str.title, df_5_clean.columns)\n",
        "\n",
        "df_1_clean.rename(columns={'Towns':'Town'}, inplace=True)# Renaming the column name to be consistent along all the data frames\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTC243LiasCO",
        "colab_type": "code",
        "outputId": "d12557ad-cdc1-423d-ef80-4514b9d371c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "df_1_clean[\"Town\"]=df_1_clean[\"Town\"].str.upper()# Captializing all the values of column Town\n",
        "df_4_clean[\"Town\"]=df_4_clean[\"Town\"].str.upper()# Captializing all the values of column Town\n",
        "df_5_clean[\"Town\"]=df_5_clean[\"Town\"].str.upper()# Captializing all the values of column Town\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj8dGaNMd-8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merging the data set\n",
        "  df_merge=pd.merge(df_1_clean,df_5_clean,on='Town',how=\"outer\",indicator=False)\n",
        "df_merge=df_merge.loc[:,\"Town\":\"Year Established\"]#Because all the values in Town and Town capital are same. Thus this column can be removed.\n",
        "df_merge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DwWnY5CiCla",
        "colab_type": "text"
      },
      "source": [
        "### QW2: Filtering out missing data (5 pts)\n",
        "•\tIt’s often helpful to make a subset of the data that you need to clean. Then you can join it back together later.  Assign a subset of missing data to a new variable called “missingdata”, then make a pivot table and count the missing rows per County (5 pts)\n",
        "o\tDo you see any interesting patterns?\n",
        "o\tHint: the missing data values in the economic data (#1) are: blank (no value), -999, one whitespace, two whitespaces, Missing, MISSING and Missin.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri9QFLi3iIl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df_merge.replace(['Missing','Missin','MISSING',' ','  ',-999],np.nan,inplace=True)\n",
        "\n",
        "df_merge['Mean Household Income']=pd.Series(df_merge['Mean Household Income']).str.replace(',','')\n",
        "df_merge['Mean Household Income']=df_merge['Mean Household Income'].astype(float) \n",
        "#missingdata=df_merge.loc[(df_merge['Mean Household Income'].isin(['Missing','Missin','MISSING',' ','  ']))|(df_merge['Per Capita Income'].isin([' ','  ',-999]))]\n",
        "nonmissingdata=df_merge.dropna()\n",
        "\n",
        "missingdata=df_merge.loc[(df_merge['Mean Household Income'].isna())|(df_merge['Per Capita Income'].isna())]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfksDjgS5SEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missingdata.pivot_table(index='County',aggfunc=len)# No of rows per county which have missing values."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEKEUhOjUubk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missingdata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "durQ9I6XvFPo",
        "colab_type": "text"
      },
      "source": [
        "## QW3: Replacing missing data (5 pts)\n",
        "•\tReplace missing numeric data in “missingdata” with the mean of the county. (2.5 pts)\n",
        "•\tAdd the dataset back to the original data. (2.5 pts)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSdkWMU8uv5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing the duplicates before calculating the average from df_merge dataset to get the correct results\n",
        "df_merge=df_merge.drop_duplicates()\n",
        "\n",
        "m1=df_merge.groupby(\"County\").mean()\n",
        "m1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rvbwCfpvM1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for (i,row) in missingdata.iterrows():\n",
        "  if pd.isnull(row[\"Median Household Income\"])==True:\n",
        "     missingdata.at[i,\"Median Household Income\"]=m1.loc[row[\"County\"],'Median Household Income']\n",
        "  if pd.isnull(row[\"Mean Household Income\"])==True:\n",
        "     missingdata.at[i,\"Mean Household Income\"]=m1.loc[row[\"County\"],\"Mean Household Income\"] \n",
        "  if pd.isnull(row[\"Per Capita Income\"])==True:\n",
        "     missingdata.at[i,\"Per Capita Income\"]=m1.loc[row[\"County\"],\"Per Capita Income\"] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8guRXiuzduz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "final_dataset=nonmissingdata.append(missingdata)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8181JAe8otF",
        "colab_type": "text"
      },
      "source": [
        "## QW4: Removing duplicates (5 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c286vGj8kBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_withnoduplicates=final_dataset.drop_duplicates()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Xv2q7PyG4l",
        "colab_type": "text"
      },
      "source": [
        "### QW5: Discretization and Binning (5 pts)\n",
        "Make a flag variable (binary variable) for any town who has a per capita income greater than the median value within the column. “1” means greater than the median, “0” means less than or equal to the median. (5 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYOfapGlyMKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_withnoduplicates['Flag']=0\n",
        "\n",
        "\n",
        "for (i, row) in data_withnoduplicates.iterrows():\n",
        "  #print(row['Per Capita Income'],row['Median Household Income'])\n",
        "  if (row['Per Capita Income']>data_withnoduplicates[\"Per Capita Income\"].median()):\n",
        "      #print('here')\n",
        "      data_withnoduplicates.at[i,\"Flag\"]=1\n",
        "\n",
        "data_withnoduplicates\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VIODq7vBA7R",
        "colab_type": "text"
      },
      "source": [
        "### Data Wrangling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dounoVLuinTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyGEWJ79GwFm",
        "colab_type": "code",
        "outputId": "0922b89f-49ee-4be4-91a0-397440f7f915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "#fill in the gaps for town name and delete anything that’s not a town \n",
        "location=df_2_15_clean['Location']\n",
        "for i in range(len(location)):\n",
        "    if pd.isnull(location[i])==True:\n",
        "      location[i]=location[i-1]\n",
        "df_2_15_clean"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sYu3LphNZlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state=df_2_91_clean['State']\n",
        "county=df_2_91_clean['County']\n",
        "l2=df_2_91_clean['Location[3][41]']\n",
        "for i in range(len(state)):\n",
        "    if pd.isnull(state[i])==True:\n",
        "      state[i]=state[i-1]\n",
        "\n",
        "for i in range(len(county)):\n",
        "    if pd.isnull(county[i])==True:\n",
        "      county[i]=county[i-1]\n",
        "for i in range(len(l2)):\n",
        "    if pd.isnull(l2[i])==True:\n",
        "      l2[i]=l2[i-1]     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCSADpFokKvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_2_91_clean.rename(columns={'Location[3][41]':'Location','Mi[3][4][42]':'MI','Exit[43]':'Exit'}, inplace=True)\n",
        "df_2_91_clean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWGT5mo8kTdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "c=df_2_95_clean['County']\n",
        "l=df_2_95_clean['Location']\n",
        "for i in range(len(c)):\n",
        "    if pd.isnull(c[i])==True:\n",
        "      c[i]=c[i-1]\n",
        "for i in range(len(l)):\n",
        "    if pd.isnull(l[i])==True:\n",
        "      l[i]=l[i-1] \n",
        "      \n",
        "df_2_95_clean"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}